{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preliminar setup</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import ast \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "european = ['^SPX', '^NDX', '^RUT']\n",
    "#european = ['^NDX']\n",
    "\n",
    "american = ['NVDA', 'JNJ', 'XOM']\n",
    "\n",
    "#Parametric string\n",
    "opt_filename = './data/options_daily/raw/{date_dir}/{date_file}_{title}_{type}.csv'\n",
    "\n",
    "opt_filename_proc = './data/options_daily/proc/{date_dir}/{date_file}_{title}_{type}.csv'\n",
    "\n",
    "title_filename = './data/title/{title}.csv'\n",
    "\n",
    "#List of dates day by day from 2024_11_12 to 2024_11_29 \n",
    "dates = pd.date_range(start='2024-11-11', end='2024-11-29').strftime('%Y_%m_%d').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scrape title data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_title_data(title, start_date, end_date):\n",
    "    stock = yf.Ticker(title)\n",
    "    historical_data = stock.history(start=start_date, end=end_date)\n",
    "    #Add column log ret given by ln(close_price(t))-ln(close_price(t-1))\n",
    "    historical_data['log_ret'] = np.log(historical_data['Close']) - np.log(historical_data['Close'].shift(1))\n",
    "    #remove first row\n",
    "    historical_data = historical_data.iloc[1:]\n",
    "    historical_data.to_csv(title_filename.format(title=title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2021-12-01\"\n",
    "end_date = \"2024-12-02\"\n",
    "\n",
    "for title in american + european:\n",
    "    print(f\"Scraping {title}\")\n",
    "    scrape_title_data(title, start_date, end_date)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scrape Options Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_options_data(options, today):\n",
    "    \n",
    "    for idx in options:\n",
    "        spx = yf.Ticker(idx)\n",
    "\n",
    "        # get option chain for specific expiration\n",
    "        try:\n",
    "            opt = spx.option_chain('0000-00-00')\n",
    "        except Exception as e:\n",
    "            list_string = \"[\" + str(e).split('[')[1]\n",
    "            list_string = list_string.replace(\" \", \"\")\n",
    "            list_string = list_string.replace(\",\", \"','\")\n",
    "            list_string = list_string.replace(\"[\", \"['\")\n",
    "            list_string = list_string.replace(\"]\", \"']\")\n",
    "            option_dates = ast.literal_eval(list_string)\n",
    "        \n",
    "        all_calls = pd.DataFrame()\n",
    "        all_puts = pd.DataFrame()\n",
    "        \n",
    "        # Define the cutoff date\n",
    "        cutoff_date = datetime(2024, 12, 31)\n",
    "        \n",
    "        for date in option_dates:\n",
    "            # Convert date to a datetime object if it's not already one\n",
    "            if isinstance(date, str):\n",
    "                date_obj = datetime.strptime(date, '%Y-%m-%d')\n",
    "            \n",
    "            if date_obj < cutoff_date:\n",
    "                opt = spx.option_chain(date)\n",
    "                \n",
    "                #Process calls\n",
    "                call = opt.calls\n",
    "                call['expiration_date'] = date #add expiration date to the dataframe\n",
    "                all_calls = pd.concat([all_calls, call], ignore_index=True)\n",
    "                #all_calls = all_calls[all_calls.isna().sum(axis=1) <= 1]\n",
    "                #all_calls = all_calls.dropna()\n",
    "                \n",
    "                #Process puts\n",
    "                put = opt.puts\n",
    "                put['expiration_date'] = date #add expiration_date to the dataframe\n",
    "                all_puts = pd.concat([all_puts, put], ignore_index=True)\n",
    "                #all_puts = all_puts[all_puts.isna().sum(axis=1) <= 1]\n",
    "                #all_puts = all_puts.dropna()\n",
    "        \n",
    "        #If doesn't exist, create a data folder\n",
    "        all_calls.to_csv('./data/options_daily/raw/' + today + '/' + today + '_' + idx + '_calls.csv', index=False)\n",
    "        all_puts.to_csv('./data/options_daily/raw/' + today + '/' + today + '_' + idx + '_puts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get today date in format yyyy_mm_dd\n",
    "today = pd.Timestamp.today().strftime('%Y_%m_%d')\n",
    "\n",
    "try:\n",
    "    os.makedirs('./data/options_daily/raw/' + today)\n",
    "except Exception as e:\n",
    "    print('Data already written for today')\n",
    "    exit()\n",
    "\n",
    "print('Scraping European options data')\n",
    "scrape_options_data(european, today)\n",
    "\n",
    "print('Scraping American options data')\n",
    "scrape_options_data(american, today)\n",
    "    \n",
    "print('Scraping completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Take only data until 29/11/2024 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all datasets take only the rows with expiration_date until 2024-11-29\n",
    "for date in dates:\n",
    "    for idx in european + american:\n",
    "        for option_type in ['calls', 'puts']:\n",
    "            df = pd.read_csv(opt_filename.format(date_dir=date, date_file=date, title=idx, type=option_type))\n",
    "            df['expiration_date'] = pd.to_datetime(df['expiration_date'])\n",
    "            df = df[df['expiration_date'] <= '2024-11-29']\n",
    "            df.to_csv(opt_filename_proc.format(date_dir=date, date_file=date, title=idx, type=option_type), index=False)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Take for every day and for every title the intesection in the couple (put, call) of strike K, expiration date and last trade date</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    for title in american + european:\n",
    "        call_df = pd.read_csv(opt_filename.format(date_dir=date, date_file=date, title=title, type='calls'))\n",
    "        put_df = pd.read_csv(opt_filename.format(date_dir=date, date_file=date, title=title, type='puts'))\n",
    "        \n",
    "        #Make lastTradeDate from yyyy-mm-dd hh:mm:ss to yyyy-mm-dd\n",
    "        call_df['lastTradeDate'] = call_df['lastTradeDate'].str.split(' ').str[0]\n",
    "        put_df['lastTradeDate'] = put_df['lastTradeDate'].str.split(' ').str[0]\n",
    "        \n",
    "        #Extract unique values for strikes and expirations\n",
    "        call_strikes = call_df['strike'].unique()\n",
    "        call_expirations = call_df['expiration_date'].unique()\n",
    "        \n",
    "        put_strikes = put_df['strike'].unique()\n",
    "        put_expirations = put_df['expiration_date'].unique()\n",
    "        \n",
    "        '''Extract call and puts with same lastTradeDate or at most lastTradeDate +- 2 days\n",
    "           so if i have the call_last_trade_dates=[2024-11-12, 2024-11-12, 2024-11-14, 2024-11-15] and \n",
    "           the put_last_trade_dates=[2024-11-12, 2024-11-12, 2024-11-12, 2024-11-12] i take \n",
    "           [2024-11-12, 2024-11-14]\n",
    "        '''\n",
    "        \n",
    "        call_last_trade_dates = call_df['lastTradeDate'].unique()\n",
    "        put_last_trade_dates = put_df['lastTradeDate'].unique()\n",
    "        \n",
    "        call_last_trade_dates = pd.to_datetime(call_last_trade_dates)\n",
    "        put_last_trade_dates = pd.to_datetime(put_last_trade_dates)\n",
    "\n",
    "        # Extract call and puts with same lastTradeDate or at most lastTradeDate +- 2 days\n",
    "        common_trade_dates = []\n",
    "        for trade_date in put_last_trade_dates:\n",
    "            if any((call_last_trade_dates >= trade_date - timedelta(days=2)) & (call_last_trade_dates <= trade_date + timedelta(days=2))):\n",
    "                common_trade_dates.append(trade_date)\n",
    "\n",
    "        # Convert common_trade_dates back to string format if needed\n",
    "        common_trade_dates = [trade_date.strftime('%Y-%m-%d') for trade_date in common_trade_dates]        \n",
    "          \n",
    "        #Extract the common values between calls and puts\n",
    "        strikes = np.intersect1d(call_strikes, put_strikes)\n",
    "        expirations = np.intersect1d(call_expirations, put_expirations)        \n",
    "        \n",
    "                    \n",
    "        #Filter the dataframes\n",
    "        filtered_call_df = call_df[call_df['strike'].isin(strikes) & \n",
    "                          call_df['expiration_date'].isin(expirations) & \n",
    "                          call_df['lastTradeDate'].isin(common_trade_dates)]\n",
    "        \n",
    "        filtered_put_df = put_df[put_df['strike'].isin(strikes) &\n",
    "                        put_df['expiration_date'].isin(expirations) &\n",
    "                        put_df['lastTradeDate'].isin(common_trade_dates)]\n",
    "        \n",
    "                \n",
    "           \n",
    "        \n",
    "        #Save the dataframes\n",
    "        filtered_call_df.to_csv(opt_filename_proc.format(date_dir=date, date_file=date, title=title, type='calls'), index=False)\n",
    "        filtered_put_df.to_csv(opt_filename_proc.format(date_dir=date, date_file=date, title=title, type='puts'), index=False)\n",
    "        \n",
    "print(\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calcolo del tasso privo di rischio</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcolo la media dei rendimenti\n",
    "\n",
    "tb_dates = ['2024']\n",
    "\n",
    "#create a dateset concatenating each year\n",
    "df_all = pd.DataFrame()\n",
    "for date in tb_dates:\n",
    "    df = pd.read_csv(f'./data/bond/daily-treasury-rates_{date}.csv')\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "#Take only the elements in Date column which starts with 11/\n",
    "df_all = df_all[df_all['Date'].str.startswith('11/')]\n",
    "\n",
    "#drop date column\n",
    "df_all = df_all.drop(columns=['Date'])\n",
    "\n",
    "#Take mean skipping nan values\n",
    "means = df_all.mean(skipna=True)\n",
    "\n",
    "df_means = pd.DataFrame(means).T\n",
    "\n",
    "#output to csv\n",
    "df_means.to_csv('./data/bond/daily-treasury-rates_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calcolo della volatilitá di lungo periodo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dato che i titoli nel mercato sono autocorrelati e eteroschedastici cioé hanno varianza variabile posso usare un modello garch per calcolare la volatilitá di lungo periodo\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "\n",
    "# Import the fGarch library in R\n",
    "ro.r(\"\"\"\n",
    "if (!require(fGarch)) install.packages(\"fGarch\", repos=\"http://cran.r-project.org\")\n",
    "library(fGarch)\n",
    "\n",
    "# Carica anche i pacchetti richiesti per ridurre l'avviso\n",
    "if (!require(fBasics)) install.packages(\"fBasics\", repos=\"http://cran.r-project.org\")\n",
    "if (!require(timeDate)) install.packages(\"timeDate\", repos=\"http://cran.r-project.org\")\n",
    "if (!require(timeSeries)) install.packages(\"timeSeries\", repos=\"http://cran.r-project.org\")\n",
    "if (!require(Metrics)) install.packages(\"Metrics\", repos=\"http://cran.r-project.org\")\n",
    "\n",
    "library(fBasics)\n",
    "library(timeDate)\n",
    "library(timeSeries)\n",
    "library(Metrics)\n",
    "\"\"\")\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "def compute_long_run_volatility(title):\n",
    "    df = pd.read_csv(title_filename.format(title=title))\n",
    "    \n",
    "    # Prendo come training set tutti i dati fino al 31 ottobre 2024\n",
    "    r_data_training = df[df['Date'] <= '2024-10-31']['log_ret']\n",
    "    r_data_testing= df[df['Date'] > '2024-10-31']['log_ret']\n",
    "\n",
    "\n",
    "    # Converti la Serie Pandas in un DataFrame per facilitarne la conversione in R\n",
    "    r_data_training = pd.DataFrame(r_data_training, columns=[\"log_ret\"])\n",
    "    r_data_testing = pd.DataFrame(r_data_testing, columns=[\"log_ret\"])\n",
    "\n",
    "    # Converti il DataFrame Pandas in un oggetto R\n",
    "    r_data_training = pandas2ri.py2rpy(r_data_training)\n",
    "    r_data_testing = pandas2ri.py2rpy(r_data_testing)\n",
    "\n",
    "\n",
    "    # Passa il dato a R\n",
    "    ro.globalenv['train_log_rets'] = r_data_training\n",
    "    ro.globalenv['test_log_rets'] = r_data_testing\n",
    "    \n",
    "\n",
    "    # Scrivi lo script per calcolare il modello GARCH con la serie reale\n",
    "    r_script = \"\"\"\n",
    "    \n",
    "    # Fit GARCH(1,1) con i dati reali\n",
    "    garch_model <- fGarch::garchFit(formula=~garch(1,1), data=train_log_rets, init.rec=\"mci\", cond.dist=\"norm\", algorithm=\"lbfgsb\")\n",
    "    summary(garch_model)\n",
    "        \n",
    "    #Evaluate autocorrelation of model residuals with Ljung-Box test\n",
    "    #residuals <- residuals(model, standardize = TRUE)\n",
    "\n",
    "    # Test di Ljung-Box sui residui\n",
    "    #ljung_box_residuals <- Box.test(residuals, lag = 10, type = \"Ljung-Box\")\n",
    "    \n",
    "    #Evaluate accuracy of the model\n",
    "    forecast_length <- nrow(test_log_rets)\n",
    "    train_length <- nrow(train_log_rets)\n",
    "    \n",
    "    # Calcola la volatilità condizionata fittando il modello sul testing set\n",
    "    forecasts <- fGarch::predict(garch_model, n.ahead=forecast_length)\n",
    "    \n",
    "    # Extract forecasted means and conditional variances\n",
    "    forecasted_means <- forecasts$meanForecast\n",
    "    #forecasted_variances <- forecasts$standardDeviation^2\n",
    "    #forecasted_means\n",
    "    \n",
    "    #Convert test_log_rets and train_log_rets to numeric vector\n",
    "    test_log_rets <- test_log_rets$log_ret  \n",
    "    train_log_rets <- train_log_rets$log_ret  \n",
    "\n",
    "    \n",
    "    # Evaluate the model with MAE, MSE, RMSE, MPE, MAPE, SMAPE, MASE, RMMSE\n",
    "    MAE <- sum(abs(test_log_rets-forecasted_means))/forecast_length #Mean Absolute Error\n",
    "    MSE <- sum((test_log_rets-forecasted_means)^2)/forecast_length #Mean Squared Error\n",
    "    RMSE <- sqrt(sum((test_log_rets-forecasted_means)^2)/forecast_length) #Root Mean Squared Error\n",
    "    \n",
    "    MPE <- 100*sum(((test_log_rets - forecasted_means) / test_log_rets))/forecast_length #Mean Percentage Error\n",
    "    MAPE <- 100*sum(abs(((test_log_rets - forecasted_means) / test_log_rets)))/forecast_length #Mean Percentage Error\n",
    "    \n",
    "    SMAPE <- 100*sum(abs(test_log_rets - forecasted_means)/(abs(test_log_rets)+abs(forecasted_means)))/forecast_length #Symmetric Mean Absolute Percentage Error\n",
    "    \n",
    "    mase_num <- sum(abs(test_log_rets - forecasted_means))/forecast_length #Use test set at numerator\n",
    "    mase_den <- sum(abs(diff(train_log_rets)))/(train_length-1) #Use training set at denominator\n",
    "    \n",
    "    MASE <- mase_num / mase_den #Mean Absolute Scaled Error\n",
    "    \n",
    "    rmsse_numerator <- sum((test_log_rets - forecasted_means)^2)/forecast_length\n",
    "    rmsse_denominator <- sum(diff(train_log_rets)^2)/(train_length - 1)\n",
    "    \n",
    "    RMSSE <- sqrt(rmsse_numerator / rmsse_denominator) #Root Mean Squared Scaled Error\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Extract coefficients of the model\n",
    "    coefficients <- coef(garch_model)  \n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    # Esecuzione del codice in R\n",
    "    ro.r(r_script)\n",
    "    \n",
    "    #Print ljung box test results\n",
    "    #print(ro.r('ljung_box_residuals'))\n",
    "    \n",
    "    #Returns mu, omega, alpha1, beta1\n",
    "    coefficients = ro.r('coefficients')\n",
    "    MU = coefficients[0]\n",
    "    OMEGA = coefficients[1]\n",
    "    ALPHA1 = coefficients[2]\n",
    "    BETA1 = coefficients[3]\n",
    "    print(\"MU -> \" + str(MU))\n",
    "    print(\"OMEGA -> \" + str(OMEGA))\n",
    "    print(\"ALPHA1 -> \" + str(ALPHA1))\n",
    "    print(\"BETA1 -> \" + str(BETA1))\n",
    "    print()\n",
    "    \n",
    "    long_run_volatility = OMEGA/(1-ALPHA1-BETA1)\n",
    "    print(\"LONG RUN VOLATILITY -> \" + str(long_run_volatility))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #Returns MAE, MAPE, RMSE, MSE, MPE, SMAPE, MASE, RMMSE\n",
    "    print(\"MAE -> \" + str(ro.r('MAE')[0]))\n",
    "    print(\"RMSE -> \" + str(ro.r('RMSE')[0]))\n",
    "    print(\"MSE -> \" + str(ro.r('MSE')[0]))\n",
    "    \n",
    "    print(\"MPE -> \" + str(ro.r('MPE')[0]))\n",
    "    print(\"MAPE -> \" + str(ro.r('MAPE')[0]))    \n",
    "    print(\"SMAPE -> \" + str(ro.r('SMAPE')[0]))\n",
    "    \n",
    "    print(\"MASE -> \" + str(ro.r('MASE')[0]))\n",
    "    print(\"RMSSE -> \" + str(ro.r('RMSSE')[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_long_run_volatility('^SPX')\n",
    "\n",
    "'''\n",
    "OMEGA -> 9.596220100948595e-07\n",
    "ALPHA1 -> 0.07713687415236392\n",
    "BETA1 -> 0.9149867274327818\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.00012183512813230487\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Standardised Residuals Tests:\n",
    "                                 Statistic     p-Value\n",
    " Jarque-Bera Test   R    Chi^2   7.7015681 0.021263058 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Shapiro-Wilk Test  R    W       0.9935248 0.003018532 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Ljung-Box Test     R    Q(10)   6.2869703 0.790604543 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)  10.9893952 0.753345768 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)  23.0590353 0.285905087 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)  14.2173008 0.163308600 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)  19.2041441 0.204631699 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)  21.6649474 0.358964724 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2   15.2297226 0.229113370 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.006094533709048875 \n",
    "RMSE -> 0.008610649261663116\n",
    "MSE -> 7.414328070737957e-05\n",
    "MPE -> -87.3943129139289\n",
    "MAPE -> 252.40103117705092\n",
    "SMAPE -> 78.40195738620056 \n",
    "MASE -> 0.5163388319803032 -> The model is better than a naive model case MASE < 1\n",
    "RMSSE -> 0.5508407413022812 -> The model is better than a naive model case RMSSE < 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_long_run_volatility('^NDX')\n",
    "\n",
    "'''\n",
    "OMEGA -> 1.5333717379024792e-06\n",
    "ALPHA1 -> 0.05178665160818798\n",
    "BETA1 -> 0.9405498291075637\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.00020008715069774548\n",
    "'''\n",
    "\n",
    "'''\n",
    " Jarque-Bera Test   R    Chi^2   5.1105253 0.07767183 -> H0 è che i residui siano normali, la accettiamo perche p>0.05\n",
    " Shapiro-Wilk Test  R    W       0.9961994 0.07445377 -> H0 è che i residui siano normali, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(10)   7.3217410 0.69476141 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)  12.8546429 0.61352425 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)  21.2638981 0.38174870 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)  15.1731763 0.12587456 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)  20.7659377 0.14447586 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)  24.2607337 0.23118830 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2   18.1407399 0.11148352 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.008033379728990257\n",
    "RMSE -> 0.011390500807927877\n",
    "MSE -> 0.00012974350865540562\n",
    "MPE -> 105.20046753081294\n",
    "MAPE -> 107.65264495006166\n",
    "SMAPE -> 79.56846554460454\n",
    "MASE -> 0.48238686730508334\n",
    "RMSSE -> 0.5221030090360853\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series Initialization:\n",
      " ARMA Model:                arma\n",
      " Formula Mean:              ~ arma(0, 0)\n",
      " GARCH Model:               garch\n",
      " Formula Variance:          ~ garch(1, 1)\n",
      " ARMA Order:                0 0\n",
      " Max ARMA Order:            0\n",
      " GARCH Order:               1 1\n",
      " Max GARCH Order:           1\n",
      " Maximum Order:             1\n",
      " Conditional Dist:          norm\n",
      " h.start:                   2\n",
      " llh.start:                 1\n",
      " Length of Series:          732\n",
      " Recursion Init:            mci\n",
      " Series Scale:              0.01466239\n",
      "\n",
      "Parameter Initialization:\n",
      " Initial Parameters:          $params\n",
      " Limits of Transformations:   $U, $V\n",
      " Which Parameters are Fixed?  $includes\n",
      " Parameter Matrix:\n",
      "                     U            V      params includes\n",
      "    mu     -0.03642718   0.03642718 0.003642718     TRUE\n",
      "    omega   0.00000100 100.00000000 0.100000000     TRUE\n",
      "    alpha1  0.00000001   0.99999999 0.100000000     TRUE\n",
      "    gamma1 -0.99999999   0.99999999 0.100000000    FALSE\n",
      "    beta1   0.00000001   0.99999999 0.800000000     TRUE\n",
      "    delta   0.00000000   2.00000000 2.000000000    FALSE\n",
      "    skew    0.10000000  10.00000000 1.000000000    FALSE\n",
      "    shape   1.00000000  10.00000000 4.000000000    FALSE\n",
      " Index List of Parameters to be Optimized:\n",
      "    mu  omega alpha1  beta1 \n",
      "     1      2      3      5 \n",
      " Persistence:                  0.9 \n",
      "\n",
      "\n",
      "--- START OF TRACE ---\n",
      "Selected Algorithm: lbfgsb \n",
      "\n",
      "R coded optim[L-BFGS-B] Solver: \n",
      "\n",
      "iter   10 value 1019.375517\n",
      "final  value 1019.375517 \n",
      "converged\n",
      "\n",
      "Final Estimate of the Negative LLH:\n",
      " LLH:  -2071.472    norm LLH:  -2.82988 \n",
      "          mu        omega       alpha1        beta1 \n",
      "1.095972e-04 4.048775e-06 5.112835e-02 9.294291e-01 \n",
      "\n",
      "R-optimhess Difference Approximated Hessian Matrix:\n",
      "                 mu         omega        alpha1         beta1\n",
      "mu     -3967238.465  1.956222e+07 -1.438899e+03  3.337124e+03\n",
      "omega  19562216.762 -2.172125e+12 -3.444111e+08 -3.958175e+08\n",
      "alpha1    -1438.899 -3.444111e+08 -6.822822e+04 -7.094738e+04\n",
      "beta1      3337.124 -3.958175e+08 -7.094738e+04 -7.898237e+04\n",
      "attr(,\"time\")\n",
      "Time difference of 0.008014917 secs\n",
      "\n",
      "--- END OF TRACE ---\n",
      "\n",
      "\n",
      "Time to Estimate Parameters:\n",
      " Time difference of 0.2436905 secs\n",
      "\n",
      "Title:\n",
      " GARCH Modelling \n",
      "\n",
      "Call:\n",
      " fGarch::garchFit(formula = ~garch(1, 1), data = train_log_rets, \n",
      "    init.rec = \"mci\", cond.dist = \"norm\", algorithm = \"lbfgsb\") \n",
      "\n",
      "Mean and Variance Equation:\n",
      " data ~ garch(1, 1)\n",
      "<environment: 0x5593a53bcb68>\n",
      " [data = train_log_rets]\n",
      "\n",
      "Conditional Distribution:\n",
      " norm \n",
      "\n",
      "Coefficient(s):\n",
      "        mu       omega      alpha1       beta1  \n",
      "1.0960e-04  4.0488e-06  5.1128e-02  9.2943e-01  \n",
      "\n",
      "Std. Errors:\n",
      " based on Hessian \n",
      "\n",
      "Error Analysis:\n",
      "        Estimate  Std. Error  t value Pr(>|t|)    \n",
      "mu     1.096e-04   5.024e-04    0.218  0.82731    \n",
      "omega  4.049e-06   2.493e-06    1.624  0.10437    \n",
      "alpha1 5.113e-02   1.615e-02    3.166  0.00154 ** \n",
      "beta1  9.294e-01   2.276e-02   40.844  < 2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Log Likelihood:\n",
      " 2071.472    normalized:  2.82988 \n",
      "\n",
      "Description:\n",
      " Thu Jan  2 16:11:06 2025 by user: matteo \n",
      "\n",
      "\n",
      "Standardised Residuals Tests:\n",
      "                                Statistic   p-Value\n",
      " Jarque-Bera Test   R    Chi^2   2.980368 0.2253312\n",
      " Shapiro-Wilk Test  R    W       0.996578 0.1176416\n",
      " Ljung-Box Test     R    Q(10)   4.459829 0.9242289\n",
      " Ljung-Box Test     R    Q(15)   9.566764 0.8460712\n",
      " Ljung-Box Test     R    Q(20)  22.830264 0.2972056\n",
      " Ljung-Box Test     R^2  Q(10)  11.275451 0.3364644\n",
      " Ljung-Box Test     R^2  Q(15)  14.676889 0.4749321\n",
      " Ljung-Box Test     R^2  Q(20)  20.998310 0.3972321\n",
      " LM Arch Test       R    TR^2   15.590459 0.2107218\n",
      "\n",
      "Information Criterion Statistics:\n",
      "      AIC       BIC       SIC      HQIC \n",
      "-5.648831 -5.623718 -5.648890 -5.639143 \n",
      "\n",
      "MU -> 0.00010959719054865068\n",
      "OMEGA -> 4.048774895259176e-06\n",
      "ALPHA1 -> 0.051128352743122475\n",
      "BETA1 -> 0.9294291094425949\n",
      "\n",
      "LONG RUN VOLATILITY -> 0.00020824312823426364\n",
      "\n",
      "MAE -> 0.01202009832952726\n",
      "RMSE -> 0.016753480177713713\n",
      "MSE -> 0.00028067909806504625\n",
      "MPE -> 96.82370051310005\n",
      "MAPE -> 96.82370051310005\n",
      "SMAPE -> 94.08475196102255\n",
      "MASE -> 0.7412907425668092\n",
      "RMSSE -> 0.8125449331795127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:\\nMAE -> 0.008033379728990257\\nRMSE -> 0.011390500807927877\\nMSE -> 0.00012974350865540562\\nMPE -> 105.20046753081294\\nMAPE -> 107.65264495006166\\nSMAPE -> 79.56846554460454\\nMASE -> 0.48238686730508334 -> The model is better than a naive model case MASE < 1\\nRMSSE -> 0.5221030090360853 -> The model is better than a naive model case RMSSE < 1\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_long_run_volatility('^RUT')\n",
    "\n",
    "'''\n",
    "OMEGA -> 4.048774895259176e-06\n",
    "ALPHA1 -> 0.051128352743122475\n",
    "BETA1 -> 0.9294291094425949\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.00020824312823426364\n",
    "'''\n",
    "\n",
    "'''\n",
    "Standardised Residuals Tests:\n",
    "                                Statistic   p-Value\n",
    " Jarque-Bera Test   R    Chi^2   2.980368 0.2253312 -> H0 è che i residui siano normali, la accettiamo perche p>0.05\n",
    " Shapiro-Wilk Test  R    W       0.996578 0.1176416 -> H0 è che i residui siano normali, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(10)   4.459829 0.9242289 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)   9.566764 0.8460712 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)  22.830264 0.2972056 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)  11.275451 0.3364644 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)  14.676889 0.4749321 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)  20.998310 0.3972321 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2   15.590459 0.2107218 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.01202009832952726\n",
    "RMSE -> 0.016753480177713713\n",
    "MSE -> 0.00028067909806504625\n",
    "MPE -> 96.82370051310005\n",
    "MAPE -> 96.82370051310005\n",
    "SMAPE -> 94.08475196102255\n",
    "MASE -> 0.7412907425668092\n",
    "RMSSE -> 0.8125449331795127\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series Initialization:\n",
      " ARMA Model:                arma\n",
      " Formula Mean:              ~ arma(0, 0)\n",
      " GARCH Model:               garch\n",
      " Formula Variance:          ~ garch(1, 1)\n",
      " ARMA Order:                0 0\n",
      " Max ARMA Order:            0\n",
      " GARCH Order:               1 1\n",
      " Max GARCH Order:           1\n",
      " Maximum Order:             1\n",
      " Conditional Dist:          norm\n",
      " h.start:                   2\n",
      " llh.start:                 1\n",
      " Length of Series:          732\n",
      " Recursion Init:            mci\n",
      " Series Scale:              0.03508974\n",
      "\n",
      "Parameter Initialization:\n",
      " Initial Parameters:          $params\n",
      " Limits of Transformations:   $U, $V\n",
      " Which Parameters are Fixed?  $includes\n",
      " Parameter Matrix:\n",
      "                     U           V     params includes\n",
      "    mu     -0.58031841   0.5803184 0.05803184     TRUE\n",
      "    omega   0.00000100 100.0000000 0.10000000     TRUE\n",
      "    alpha1  0.00000001   1.0000000 0.10000000     TRUE\n",
      "    gamma1 -0.99999999   1.0000000 0.10000000    FALSE\n",
      "    beta1   0.00000001   1.0000000 0.80000000     TRUE\n",
      "    delta   0.00000000   2.0000000 2.00000000    FALSE\n",
      "    skew    0.10000000  10.0000000 1.00000000    FALSE\n",
      "    shape   1.00000000  10.0000000 4.00000000    FALSE\n",
      " Index List of Parameters to be Optimized:\n",
      "    mu  omega alpha1  beta1 \n",
      "     1      2      3      5 \n",
      " Persistence:                  0.9 \n",
      "\n",
      "\n",
      "--- START OF TRACE ---\n",
      "Selected Algorithm: lbfgsb \n",
      "\n",
      "R coded optim[L-BFGS-B] Solver: \n",
      "\n",
      "iter   10 value 1033.962197\n",
      "iter   20 value 1033.627228\n",
      "final  value 1033.627228 \n",
      "converged\n",
      "\n",
      "Final Estimate of the Negative LLH:\n",
      " LLH:  -1418.46    norm LLH:  -1.937787 \n",
      "          mu        omega       alpha1        beta1 \n",
      "2.749358e-03 7.515113e-05 3.359988e-02 9.050286e-01 \n",
      "\n",
      "R-optimhess Difference Approximated Hessian Matrix:\n",
      "                 mu        omega        alpha1         beta1\n",
      "mu      -616556.474     -4284014      5220.614     -2999.478\n",
      "omega  -4284014.090 -28825819374 -29975532.640 -34082074.404\n",
      "alpha1     5220.614    -29975533    -38803.746    -37845.443\n",
      "beta1     -2999.478    -34082074    -37845.443    -41337.309\n",
      "attr(,\"time\")\n",
      "Time difference of 0.009290457 secs\n",
      "\n",
      "--- END OF TRACE ---\n",
      "\n",
      "\n",
      "Time to Estimate Parameters:\n",
      " Time difference of 0.2453318 secs\n",
      "\n",
      "Title:\n",
      " GARCH Modelling \n",
      "\n",
      "Call:\n",
      " fGarch::garchFit(formula = ~garch(1, 1), data = train_log_rets, \n",
      "    init.rec = \"mci\", cond.dist = \"norm\", algorithm = \"lbfgsb\") \n",
      "\n",
      "Mean and Variance Equation:\n",
      " data ~ garch(1, 1)\n",
      "<environment: 0x5593a8dffeb8>\n",
      " [data = train_log_rets]\n",
      "\n",
      "Conditional Distribution:\n",
      " norm \n",
      "\n",
      "Coefficient(s):\n",
      "        mu       omega      alpha1       beta1  \n",
      "2.7494e-03  7.5151e-05  3.3600e-02  9.0503e-01  \n",
      "\n",
      "Std. Errors:\n",
      " based on Hessian \n",
      "\n",
      "Error Analysis:\n",
      "        Estimate  Std. Error  t value Pr(>|t|)    \n",
      "mu     2.749e-03   1.291e-03    2.130   0.0332 *  \n",
      "omega  7.515e-05   5.253e-05    1.431   0.1525    \n",
      "alpha1 3.360e-02   2.214e-02    1.517   0.1292    \n",
      "beta1  9.050e-01   5.958e-02   15.191   <2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Log Likelihood:\n",
      " 1418.46    normalized:  1.937787 \n",
      "\n",
      "Description:\n",
      " Thu Jan  2 16:11:19 2025 by user: matteo \n",
      "\n",
      "\n",
      "Standardised Residuals Tests:\n",
      "                                  Statistic      p-Value\n",
      " Jarque-Bera Test   R    Chi^2  528.9313363 0.000000e+00\n",
      " Shapiro-Wilk Test  R    W        0.9679727 1.432350e-11\n",
      " Ljung-Box Test     R    Q(10)    8.1908486 6.102012e-01\n",
      " Ljung-Box Test     R    Q(15)   14.0810954 5.193878e-01\n",
      " Ljung-Box Test     R    Q(20)   19.5979460 4.833191e-01\n",
      " Ljung-Box Test     R^2  Q(10)    2.0114543 9.962516e-01\n",
      " Ljung-Box Test     R^2  Q(15)    3.6594247 9.986565e-01\n",
      " Ljung-Box Test     R^2  Q(20)    4.3375827 9.999101e-01\n",
      " LM Arch Test       R    TR^2     2.0699933 9.992908e-01\n",
      "\n",
      "Information Criterion Statistics:\n",
      "      AIC       BIC       SIC      HQIC \n",
      "-3.864646 -3.839532 -3.864705 -3.854958 \n",
      "\n",
      "MU -> 0.0027493579902329603\n",
      "OMEGA -> 7.515112948238467e-05\n",
      "ALPHA1 -> 0.03359987556656807\n",
      "BETA1 -> 0.9050285576943499\n",
      "\n",
      "LONG RUN VOLATILITY -> 0.0012245268204066823\n",
      "\n",
      "MAE -> 0.02115490886540065\n",
      "RMSE -> 0.025763244589133056\n",
      "MSE -> 0.0006637447717594937\n",
      "MPE -> 93.87573217972553\n",
      "MAPE -> 93.87573217972553\n",
      "SMAPE -> 79.77839923826744\n",
      "MASE -> 0.5576577774754948\n",
      "RMSSE -> 0.5129152355520931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:\\nMAE -> 0.021154908869784758\\nRMSE -> 0.025763244577971692\\nMSE -> 0.0006637447711843878\\nMPE -> 93.8757323848057\\nMAPE -> 93.8757323848057\\nSMAPE -> 79.77839972149734\\nMASE -> 0.5576576061155016 -> The model is better than a naive model case MASE < 1\\nRMSSE -> 0.5129150477849637 -> The model is better than a naive model case RMSSE < 1\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_long_run_volatility('NVDA')\n",
    "\n",
    "'''\n",
    "OMEGA -> 7.515112948238467e-05\n",
    "ALPHA1 -> 0.03359987556656807\n",
    "BETA1 -> 0.9050285576943499\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.0012245268204066823\n",
    "'''\n",
    "\n",
    "'''\n",
    "Jarque-Bera Test   R    Chi^2  528.9313363 0.000000e+00 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05 STRANO???\n",
    " Shapiro-Wilk Test  R    W        0.9679727 1.432350e-11 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Ljung-Box Test     R    Q(10)    8.1908486 6.102012e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)   14.0810954 5.193878e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)   19.5979460 4.833191e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)    2.0114543 9.962516e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)    3.6594247 9.986565e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)    4.3375827 9.999101e-01 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2     2.0699933 9.992908e-01 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.02115490886540065\n",
    "RMSE -> 0.025763244589133056\n",
    "MSE -> 0.0006637447717594937\n",
    "MPE -> 93.87573217972553\n",
    "MAPE -> 93.87573217972553\n",
    "SMAPE -> 79.77839923826744\n",
    "MASE -> 0.5576577774754948\n",
    "RMSSE -> 0.5129152355520931\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series Initialization:\n",
      " ARMA Model:                arma\n",
      " Formula Mean:              ~ arma(0, 0)\n",
      " GARCH Model:               garch\n",
      " Formula Variance:          ~ garch(1, 1)\n",
      " ARMA Order:                0 0\n",
      " Max ARMA Order:            0\n",
      " GARCH Order:               1 1\n",
      " Max GARCH Order:           1\n",
      " Maximum Order:             1\n",
      " Conditional Dist:          norm\n",
      " h.start:                   2\n",
      " llh.start:                 1\n",
      " Length of Series:          732\n",
      " Recursion Init:            mci\n",
      " Series Scale:              0.01038189\n",
      "\n",
      "Parameter Initialization:\n",
      " Initial Parameters:          $params\n",
      " Limits of Transformations:   $U, $V\n",
      " Which Parameters are Fixed?  $includes\n",
      " Parameter Matrix:\n",
      "                     U          V    params includes\n",
      "    mu     -0.12485296   0.124853 0.0124853     TRUE\n",
      "    omega   0.00000100 100.000000 0.1000000     TRUE\n",
      "    alpha1  0.00000001   1.000000 0.1000000     TRUE\n",
      "    gamma1 -0.99999999   1.000000 0.1000000    FALSE\n",
      "    beta1   0.00000001   1.000000 0.8000000     TRUE\n",
      "    delta   0.00000000   2.000000 2.0000000    FALSE\n",
      "    skew    0.10000000  10.000000 1.0000000    FALSE\n",
      "    shape   1.00000000  10.000000 4.0000000    FALSE\n",
      " Index List of Parameters to be Optimized:\n",
      "    mu  omega alpha1  beta1 \n",
      "     1      2      3      5 \n",
      " Persistence:                  0.9 \n",
      "\n",
      "\n",
      "--- START OF TRACE ---\n",
      "Selected Algorithm: lbfgsb \n",
      "\n",
      "R coded optim[L-BFGS-B] Solver: \n",
      "\n",
      "iter   10 value 1038.134821\n",
      "iter   20 value 1038.006300\n",
      "final  value 1038.006274 \n",
      "converged\n",
      "\n",
      "Final Estimate of the Negative LLH:\n",
      " LLH:  -2305.545    norm LLH:  -3.149651 \n",
      "          mu        omega       alpha1        beta1 \n",
      "1.092194e-04 1.271963e-05 6.837376e-03 8.746880e-01 \n",
      "\n",
      "R-optimhess Difference Approximated Hessian Matrix:\n",
      "                 mu         omega        alpha1         beta1\n",
      "mu     -6818931.578  3.160857e+07     -12499.33  3.547054e+03\n",
      "omega  31608569.864 -1.993095e+12 -207618851.79 -2.140234e+08\n",
      "alpha1   -12499.327 -2.076189e+08     -28177.46 -2.252335e+04\n",
      "beta1      3547.054 -2.140234e+08     -22523.35 -2.306499e+04\n",
      "attr(,\"time\")\n",
      "Time difference of 0.01100111 secs\n",
      "\n",
      "--- END OF TRACE ---\n",
      "\n",
      "\n",
      "Time to Estimate Parameters:\n",
      " Time difference of 0.1932826 secs\n",
      "\n",
      "Title:\n",
      " GARCH Modelling \n",
      "\n",
      "Call:\n",
      " fGarch::garchFit(formula = ~garch(1, 1), data = train_log_rets, \n",
      "    init.rec = \"mci\", cond.dist = \"norm\", algorithm = \"lbfgsb\") \n",
      "\n",
      "Mean and Variance Equation:\n",
      " data ~ garch(1, 1)\n",
      "<environment: 0x5593a63ee500>\n",
      " [data = train_log_rets]\n",
      "\n",
      "Conditional Distribution:\n",
      " norm \n",
      "\n",
      "Coefficient(s):\n",
      "        mu       omega      alpha1       beta1  \n",
      "0.00010922  0.00001272  0.00683738  0.87468799  \n",
      "\n",
      "Std. Errors:\n",
      " based on Hessian \n",
      "\n",
      "Error Analysis:\n",
      "        Estimate  Std. Error  t value Pr(>|t|)    \n",
      "mu     1.092e-04   3.842e-04    0.284    0.776    \n",
      "omega  1.272e-05   1.210e-05    1.051    0.293    \n",
      "alpha1 6.837e-03   1.304e-02    0.524    0.600    \n",
      "beta1  8.747e-01   1.158e-01    7.554 4.24e-14 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Log Likelihood:\n",
      " 2305.545    normalized:  3.149651 \n",
      "\n",
      "Description:\n",
      " Thu Jan  2 16:11:32 2025 by user: matteo \n",
      "\n",
      "\n",
      "Standardised Residuals Tests:\n",
      "                                  Statistic      p-Value\n",
      " Jarque-Bera Test   R    Chi^2  332.3234645 0.000000e+00\n",
      " Shapiro-Wilk Test  R    W        0.9665474 6.909536e-12\n",
      " Ljung-Box Test     R    Q(10)    9.5335088 4.823270e-01\n",
      " Ljung-Box Test     R    Q(15)   11.9041086 6.862723e-01\n",
      " Ljung-Box Test     R    Q(20)   14.1130944 8.247158e-01\n",
      " Ljung-Box Test     R^2  Q(10)   13.4230151 2.009725e-01\n",
      " Ljung-Box Test     R^2  Q(15)   17.0933117 3.133169e-01\n",
      " Ljung-Box Test     R^2  Q(20)   19.2805051 5.036658e-01\n",
      " LM Arch Test       R    TR^2    15.9016300 1.957832e-01\n",
      "\n",
      "Information Criterion Statistics:\n",
      "      AIC       BIC       SIC      HQIC \n",
      "-6.288374 -6.263260 -6.288433 -6.278686 \n",
      "\n",
      "MU -> 0.00010921936518196206\n",
      "OMEGA -> 1.2719627293334906e-05\n",
      "ALPHA1 -> 0.006837376415740562\n",
      "BETA1 -> 0.874687992060343\n",
      "\n",
      "LONG RUN VOLATILITY -> 0.0001073616109180909\n",
      "\n",
      "MAE -> 0.006185113818306013\n",
      "RMSE -> 0.007859111563955272\n",
      "MSE -> 6.176563457469547e-05\n",
      "MPE -> 102.94998142322815\n",
      "MAPE -> 102.94998142322815\n",
      "SMAPE -> 95.8306246221737\n",
      "MASE -> 0.5801644534792725\n",
      "RMSSE -> 0.537808128073258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:\\nMAE -> 0.006185231411945406\\nRMSE -> 0.00785926019196312\\nMSE -> 6.176797076497618e-05\\nMPE -> 102.97221459916578\\nMAPE -> 102.97221459916578\\nSMAPE -> 95.8022314465724 \\nMASE -> 0.5801752060920126 -> The model is better than a naive model case MASE < 1\\nRMSSE -> 0.5378178363056483 -> The model is better than a naive model case RMSSE < 1\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_long_run_volatility('JNJ')\n",
    "\n",
    "'''\n",
    "OMEGA -> 1.2719627293334906e-05\n",
    "ALPHA1 -> 0.006837376415740562\n",
    "BETA1 -> 0.874687992060343\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.0001073616109180909\n",
    "'''\n",
    "\n",
    "'''\n",
    "Standardised Residuals Tests:\n",
    "                                  Statistic      p-Value\n",
    " Jarque-Bera Test   R    Chi^2  332.3234645 0.000000e+00 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Shapiro-Wilk Test  R    W        0.9665474 6.909536e-12 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Ljung-Box Test     R    Q(10)    9.5335088 4.823270e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)   11.9041086 6.862723e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)   14.1130944 8.247158e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)   13.4230151 2.009725e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)   17.0933117 3.133169e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)   19.2805051 5.036658e-01 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2    15.9016300 1.957832e-01 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.006185113818306013\n",
    "RMSE -> 0.007859111563955272\n",
    "MSE -> 6.176563457469547e-05\n",
    "MPE -> 102.94998142322815\n",
    "MAPE -> 102.94998142322815\n",
    "SMAPE -> 95.8306246221737\n",
    "MASE -> 0.5801644534792725\n",
    "RMSSE -> 0.537808128073258\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series Initialization:\n",
      " ARMA Model:                arma\n",
      " Formula Mean:              ~ arma(0, 0)\n",
      " GARCH Model:               garch\n",
      " Formula Variance:          ~ garch(1, 1)\n",
      " ARMA Order:                0 0\n",
      " Max ARMA Order:            0\n",
      " GARCH Order:               1 1\n",
      " Max GARCH Order:           1\n",
      " Maximum Order:             1\n",
      " Conditional Dist:          norm\n",
      " h.start:                   2\n",
      " llh.start:                 1\n",
      " Length of Series:          732\n",
      " Recursion Init:            mci\n",
      " Series Scale:              0.01735602\n",
      "\n",
      "Parameter Initialization:\n",
      " Initial Parameters:          $params\n",
      " Limits of Transformations:   $U, $V\n",
      " Which Parameters are Fixed?  $includes\n",
      " Parameter Matrix:\n",
      "                     U           V     params includes\n",
      "    mu     -0.60333767   0.6033377 0.06033377     TRUE\n",
      "    omega   0.00000100 100.0000000 0.10000000     TRUE\n",
      "    alpha1  0.00000001   1.0000000 0.10000000     TRUE\n",
      "    gamma1 -0.99999999   1.0000000 0.10000000    FALSE\n",
      "    beta1   0.00000001   1.0000000 0.80000000     TRUE\n",
      "    delta   0.00000000   2.0000000 2.00000000    FALSE\n",
      "    skew    0.10000000  10.0000000 1.00000000    FALSE\n",
      "    shape   1.00000000  10.0000000 4.00000000    FALSE\n",
      " Index List of Parameters to be Optimized:\n",
      "    mu  omega alpha1  beta1 \n",
      "     1      2      3      5 \n",
      " Persistence:                  0.9 \n",
      "\n",
      "\n",
      "--- START OF TRACE ---\n",
      "Selected Algorithm: lbfgsb \n",
      "\n",
      "R coded optim[L-BFGS-B] Solver: \n",
      "\n",
      "iter   10 value 1003.651128\n",
      "final  value 1002.133274 \n",
      "stopped after 16 iterations\n",
      "\n",
      "Final Estimate of the Negative LLH:\n",
      " LLH:  -1965.26    norm LLH:  -2.684781 \n",
      "          mu        omega       alpha1        beta1 \n",
      "7.808871e-04 8.603458e-07 2.487334e-02 9.715906e-01 \n",
      "\n",
      "R-optimhess Difference Approximated Hessian Matrix:\n",
      "                 mu         omega        alpha1         beta1\n",
      "mu      -3052119.37  1.315376e+08  2.090859e+04  1.769599e+04\n",
      "omega  131537595.11 -8.645769e+12 -1.678098e+09 -1.867118e+09\n",
      "alpha1     20908.59 -1.678098e+09 -4.219548e+05 -4.433835e+05\n",
      "beta1      17695.99 -1.867118e+09 -4.433835e+05 -4.863776e+05\n",
      "attr(,\"time\")\n",
      "Time difference of 0.008165121 secs\n",
      "\n",
      "--- END OF TRACE ---\n",
      "\n",
      "\n",
      "Time to Estimate Parameters:\n",
      " Time difference of 0.2959602 secs\n",
      "\n",
      "Title:\n",
      " GARCH Modelling \n",
      "\n",
      "Call:\n",
      " fGarch::garchFit(formula = ~garch(1, 1), data = train_log_rets, \n",
      "    init.rec = \"mci\", cond.dist = \"norm\", algorithm = \"lbfgsb\") \n",
      "\n",
      "Mean and Variance Equation:\n",
      " data ~ garch(1, 1)\n",
      "<environment: 0x5593a8c4e2f8>\n",
      " [data = train_log_rets]\n",
      "\n",
      "Conditional Distribution:\n",
      " norm \n",
      "\n",
      "Coefficient(s):\n",
      "        mu       omega      alpha1       beta1  \n",
      "7.8089e-04  8.6035e-07  2.4873e-02  9.7159e-01  \n",
      "\n",
      "Std. Errors:\n",
      " based on Hessian \n",
      "\n",
      "Error Analysis:\n",
      "        Estimate  Std. Error  t value Pr(>|t|)    \n",
      "mu     7.809e-04   5.729e-04    1.363  0.17287    \n",
      "omega  8.603e-07   8.321e-07    1.034  0.30116    \n",
      "alpha1 2.487e-02   7.589e-03    3.278  0.00105 ** \n",
      "beta1  9.716e-01   8.165e-03  118.988  < 2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Log Likelihood:\n",
      " 1965.26    normalized:  2.684781 \n",
      "\n",
      "Description:\n",
      " Thu Jan  2 16:11:46 2025 by user: matteo \n",
      "\n",
      "\n",
      "Standardised Residuals Tests:\n",
      "                                 Statistic      p-Value\n",
      " Jarque-Bera Test   R    Chi^2  20.8895352 2.910014e-05\n",
      " Shapiro-Wilk Test  R    W       0.9936667 3.555295e-03\n",
      " Ljung-Box Test     R    Q(10)  11.7915249 2.992513e-01\n",
      " Ljung-Box Test     R    Q(15)  20.8009089 1.433119e-01\n",
      " Ljung-Box Test     R    Q(20)  27.9673765 1.101739e-01\n",
      " Ljung-Box Test     R^2  Q(10)   7.7976889 6.485908e-01\n",
      " Ljung-Box Test     R^2  Q(15)  15.2227726 4.354927e-01\n",
      " Ljung-Box Test     R^2  Q(20)  19.4795547 4.908793e-01\n",
      " LM Arch Test       R    TR^2   11.3263406 5.011776e-01\n",
      "\n",
      "Information Criterion Statistics:\n",
      "      AIC       BIC       SIC      HQIC \n",
      "-5.358633 -5.333520 -5.358692 -5.348945 \n",
      "\n",
      "MU -> 0.0007808870800507819\n",
      "OMEGA -> 8.603457755518873e-07\n",
      "ALPHA1 -> 0.024873336478831613\n",
      "BETA1 -> 0.9715906060158603\n",
      "\n",
      "LONG RUN VOLATILITY -> 0.0002433065000386456\n",
      "\n",
      "MAE -> 0.008742229965304485\n",
      "RMSE -> 0.011766014883476405\n",
      "MSE -> 0.00013843910623818827\n",
      "MPE -> 103.7901895069331\n",
      "MAPE -> 105.59375770067393\n",
      "SMAPE -> 79.74877850157623\n",
      "MASE -> 0.48024029333829615\n",
      "RMSSE -> 0.4878412107149021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:\\nMAE -> 0.009131908527415775\\nRMSE -> 0.011904597000455049\\nMSE -> 0.00014171942974324333\\nMPE -> 109.88762156887957\\nMAPE -> 110.00951558566373\\nSMAPE -> 84.12513069158285\\nMASE -> 0.5016469860292379 -> The model is better than a naive model case MASE < 1\\nRMSSE -> 0.49358729883491126 -> The model is better than a naive model case RMSSE < 1\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_long_run_volatility('XOM')\n",
    "\n",
    "'''\n",
    "OMEGA -> 8.603457755518873e-07\n",
    "ALPHA1 -> 0.024873336478831613\n",
    "BETA1 -> 0.9715906060158603\n",
    "\n",
    "LONG RUN VOLATILITY -> 0.0002433065000386456\n",
    "'''\n",
    "\n",
    "'''\n",
    "Standardised Residuals Tests:\n",
    "                                 Statistic      p-Value\n",
    " Jarque-Bera Test   R    Chi^2  20.8895352 2.910014e-05 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Shapiro-Wilk Test  R    W       0.9936667 3.555295e-03 -> H0 è che i residui siano normali, la rigettiamo perche p<0.05\n",
    " Ljung-Box Test     R    Q(10)  11.7915249 2.992513e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(15)  20.8009089 1.433119e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R    Q(20)  27.9673765 1.101739e-01 -> H0 è che i residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(10)   7.7976889 6.485908e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(15)  15.2227726 4.354927e-01 -> H0 è che i quadrati dei residui siano scorrelati, la accettiamo perche p>0.05\n",
    " Ljung-Box Test     R^2  Q(20)  19.4795547 4.908793e-01 -> H0 è che i quadrati residui siano scorrelati, la accettiamo perche p>0.05\n",
    " LM Arch Test       R    TR^2   11.3263406 5.011776e-01 -> H0 è che i i residui siano eteroschedastici, la accettiamo perche p>0.05\n",
    "'''\n",
    "\n",
    "'''\n",
    "Accuracy:\n",
    "MAE -> 0.008742229965304485\n",
    "RMSE -> 0.011766014883476405\n",
    "MSE -> 0.00013843910623818827\n",
    "MPE -> 103.7901895069331\n",
    "MAPE -> 105.59375770067393\n",
    "SMAPE -> 79.74877850157623\n",
    "MASE -> 0.48024029333829615\n",
    "RMSSE -> 0.4878412107149021\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Put-Call Parity Equation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import ast \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "european = ['^SPX', '^NDX', '^RUT']\n",
    "#european = ['^NDX']\n",
    "\n",
    "american = ['NVDA', 'JNJ', 'XOM']\n",
    "\n",
    "#Parametric string\n",
    "opt_filename = './data/options_daily/raw/{date_dir}/{date_file}_{title}_{type}.csv'\n",
    "\n",
    "opt_filename_proc = './data/options_daily/proc/{date_dir}/{date_file}_{title}_{type}.csv'\n",
    "\n",
    "title_filename = './data/title/{title}.csv'\n",
    "\n",
    "#List of dates day by day from 2024_11_12 to 2024_11_29 \n",
    "dates = pd.date_range(start='2024-11-11', end='2024-11-29').strftime('%Y_%m_%d').tolist()\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import library in R\n",
    "ro.r(\"\"\"\n",
    "if (!require(ggplot2)) install.packages(\"ggplot2\", repos=\"http://cran.r-project.org\")\n",
    "library(ggplot2)\n",
    "if (!require(grid)) install.packages(\"grid\", repos=\"http://cran.r-project.org\")\n",
    "library(grid)\n",
    "\"\"\")\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "def put_call_parity(date, title, risk_free_rate, s_0):\n",
    "    \n",
    "    p_0_df = pd.read_csv(opt_filename_proc.format(date_dir=date, date_file=date, title=title, type=\"puts\"))\n",
    "    c_0_df = pd.read_csv(opt_filename_proc.format(date_dir=date, date_file=date, title=title, type=\"calls\"))\n",
    "    \n",
    "    p_0_df = p_0_df[['lastPrice', 'strike', 'expiration_date']]\n",
    "    c_0_df = c_0_df[['lastPrice', 'strike', 'expiration_date']]\n",
    "    \n",
    "    put_call_df = pd.merge(\n",
    "    p_0_df,\n",
    "    c_0_df,\n",
    "    on=['strike', 'expiration_date'],\n",
    "    suffixes=('_put', '_call')\n",
    "    )\n",
    "    print(put_call_df)\n",
    "\n",
    "    #take expiration last date\n",
    "    put_call_df = put_call_df[put_call_df['expiration_date'] =='2024-11-29'] \n",
    "\n",
    "    put_call_df = put_call_df[['lastPrice_put', 'strike', 'lastPrice_call']]\n",
    "    \n",
    "    # Converti il DataFrame Pandas in un oggetto R\n",
    "    put_call_df = pandas2ri.py2rpy(put_call_df)\n",
    "\n",
    "\n",
    "    # Passa il dato a R\n",
    "    ro.globalenv['title'] = title\n",
    "    ro.globalenv['put_call_df'] = put_call_df\n",
    "    ro.globalenv['risk_free_rate'] = risk_free_rate\n",
    "    ro.globalenv['s_0'] = s_0\n",
    "\n",
    "    # Scrivi lo script per calcolare il modello GARCH con la serie reale\n",
    "    r_script = \"\"\"\n",
    "        #x <- -put_call_df$strike/(1+risk_free_rate) + s_0\n",
    "        x <- put_call_df$strike\n",
    "        y <- put_call_df$lastPrice_call - put_call_df$lastPrice_put\n",
    "        Data_df <- data.frame(x,y)\n",
    "\n",
    "        n <- nrow(Data_df)\n",
    "        title_content <- bquote(atop(\"University of Roma Tor Vergata - \\u0040 MPSMF 2023-2024\", \n",
    "                                    paste(\"Scatter Plot of the Call-Put Difference Against the Strike Price for \" ~ .(title))))\n",
    "        subtitle_content <- bquote(paste(\"Data set size\",~~.(n),~~\"sample points;    Evaluation Date 2024-11-27;   Maturity Date 2024-11-27\"))\n",
    "        caption_content <- \"Author: Matteo Conti\" \n",
    "        \n",
    "\n",
    "        x_breaks_num <- 8\n",
    "        x_breaks_low <- min(Data_df$x)\n",
    "        x_breaks_up <- max(Data_df$x)\n",
    "        x_binwidth <- floor((x_breaks_up-x_breaks_low)/x_breaks_num)\n",
    "        x_binwidth <- ifelse(x_binwidth == 0, 1, x_binwidth)\n",
    "        \n",
    "        x_breaks <- seq(from=x_breaks_low, to=x_breaks_up, by=x_binwidth)\n",
    "        \n",
    "        if((x_breaks_up-max(x_breaks))>x_binwidth/2){x_breaks <- c(x_breaks,x_breaks_up)}\n",
    "        x_labs <- format(x_breaks, scientific=FALSE)\n",
    "        J <- 0.2\n",
    "        x_lims <- c(x_breaks_low-J*x_binwidth,x_breaks_up+J*x_binwidth)\n",
    "        x_name <- bquote(\"strike\")\n",
    "        y_breaks_num <- 10\n",
    "        y_max <- max(Data_df$y)\n",
    "        y_min <- min(Data_df$y)\n",
    "        y_binwidth <- round((y_max-y_min)/y_breaks_num, digits=3)\n",
    "        y_breaks_low <- y_min\n",
    "        y_breaks_up <- y_max\n",
    "        y_breaks <- seq(from=y_breaks_low, to=y_breaks_up, by=y_binwidth)\n",
    "        if((y_breaks_up-max(y_breaks))>y_binwidth/2){y_breaks <- c(y_breaks,y_breaks_up)}\n",
    "        y_labs <- format(y_breaks, scientific=FALSE)\n",
    "        y_name <- bquote(\"call-put difference\")\n",
    "        K <- 0.2\n",
    "        y_lims <- c((y_breaks_low-K*y_binwidth), (y_breaks_up+K*y_binwidth))\n",
    "        col_1 <- bquote(\"data set sample points\")\n",
    "        col_2 <- bquote(\"regression line\")\n",
    "        col_3 <- bquote(\"LOESS curve\")\n",
    "        leg_labs <- c(col_1, col_2, col_3)\n",
    "        leg_cols <- c(\"col_1\"=\"blue\", \"col_2\"=\"green\", \"col_3\"=\"red\")\n",
    "        leg_ord <- c(\"col_1\", \"col_2\", \"col_3\")\n",
    "        Call_Put_Strike_Pr_2024_11_11_11_27_sp <- ggplot(Data_df, aes(x=x, y=y)) +\n",
    "        geom_smooth(alpha=1, linewidth=0.8, linetype=\"dashed\", aes(color=\"col_3\"),\n",
    "                    method=\"loess\", formula=y ~ x, se=FALSE, fullrange = FALSE) +\n",
    "        geom_smooth(alpha=1, linewidth=0.8, linetype=\"solid\", aes(color=\"col_2\"),\n",
    "                    method=\"lm\" , formula=y ~ x, se=FALSE, fullrange=FALSE) +\n",
    "        geom_point(alpha=1, size=1.0, shape=19, aes(color=\"col_1\")) +\n",
    "        scale_x_continuous(name=x_name, breaks=x_breaks, label=x_labs, limits=x_lims) +\n",
    "        scale_y_continuous(name=y_name, breaks=y_breaks, labels=NULL, limits=y_lims,\n",
    "                            sec.axis=sec_axis(~., breaks=y_breaks, labels=y_labs)) +\n",
    "        ggtitle(title_content) +\n",
    "        labs(subtitle=subtitle_content, caption=caption_content) +\n",
    "        scale_colour_manual(name=\"Legend\", labels=leg_labs, values=leg_cols, breaks=leg_ord,\n",
    "                            guide=guide_legend(override.aes=list(shape=c(19,NA,NA), \n",
    "                                                                linetype=c(\"blank\", \"solid\", \"dashed\")))) +\n",
    "        theme(plot.title=element_text(hjust=0.5), plot.subtitle=element_text(hjust=0.5),\n",
    "                axis.text.x=element_text(angle=0, vjust=1),\n",
    "                legend.key.width=unit(1.0,\"cm\"), legend.position=\"bottom\")\n",
    "        \n",
    "        # Print the plot\n",
    "        #x11(width = 26.67, height = 15)\n",
    "        #plot(Call_Put_Strike_Pr_2024_11_11_11_27_sp)\n",
    "        \n",
    "        \n",
    "        # Construct the output file name dynamically\n",
    "        output_file <- paste0(\"./plots/Call_Put_Strike_Pr_2024_11_11_11_27_sp_\", title, \".pdf\")\n",
    "\n",
    "        # Save the plot to the dynamically generated file name\n",
    "        ggsave(filename = output_file, \n",
    "            plot = Call_Put_Strike_Pr_2024_11_11_11_27_sp, \n",
    "            width = 26.67, height = 15, units = \"cm\")        \n",
    "    \"\"\"\n",
    "\n",
    "    # Esecuzione del codice in R\n",
    "    ro.r(r_script)\n",
    "    \n",
    "    #coefficients = ro.r('coefficients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day = '2024-11-11'\n",
    "\n",
    "#title = '^SPX'\n",
    "\n",
    "risk_free_rate_df = pd.read_csv('./data/bond/daily-treasury-rates_mean.csv')\n",
    "monthly_risk_free_rate = risk_free_rate_df['4 WEEKS BANK DISCOUNT'][0]/100\n",
    "\n",
    "\n",
    "for title in european+american:\n",
    "    title_df = pd.read_csv(title_filename.format(title=title))\n",
    "\n",
    "    #take only the close price of the day equal to first_day, first day is yyyy_mm_dd and title_df['Date'] is yyyy-mm-dd hh:mm:ss  \n",
    "    s_0 = title_df[title_df['Date'].str.startswith(first_day)]['Close'].values[0]\n",
    "\n",
    "    #Convert first_day to yyyy_mm_dd\n",
    "    first_day = first_day.replace('-', '_')\n",
    "\n",
    "    put_call_parity(first_day, title, monthly_risk_free_rate, s_0)\n",
    "    \n",
    "    first_day = first_day.replace('_', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
